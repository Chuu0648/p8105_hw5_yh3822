---
title: "p8105_hw5_yh3822"
output: github_document
date: "2024-11-14"
---

```{r set up}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
library(tidyverse)
library(dplyr)
library(broom)
```


## Problem 1


```{r}
bday_sim = function(n) {
  
  bdays = sample(1:365, size = 10, replace = TRUE)

  duplicate = length(unique(bdays)) < n
  
  return(duplicate)
  
}
```



```{r}
sim_res = 
  expand_grid(
    n = c(2, 50),
    iter = 1:10000
  ) |>
  mutate(res = map_lgl(n, bday_sim)) |>
  group_by(n) |>
  summarize(prob = mean(res, na.rm = TRUE))

sim_res |>
  ggplot(aes(x = n, y = prob)) +
  geom_line()
```

As the group size increases, the probability of having at least two people with the same birthday increases.



## Problem 2


```{r}
n = 30      
sigma = 5   
alpha = 0.05
mu = 0      
```


```{r}
sim_t_test = function(n, mu, sigma = 5) {
  x = rnorm(n, mean = mu, sd = sigma)
  t_test <- t.test(x, mu = 0)
  tidy(t_test)
}
```


```{r}
sim_results <- tibble(
  iter = 1:5000
) |>
  mutate(t_test_res = map(iter, ~sim_t_test(n, mu, sigma))) |>
  unnest(t_test_res) |>
  select(iter, estimate, p.value)
head(sim_results)
```


```{r}
sim_results2 = expand_grid(
  mu = 1:6,
  iter = 1:5000
) |>
  mutate(t_test_res = map(mu, ~sim_t_test(n, .x, sigma))) |>
  unnest(t_test_res) 

sim_results2 |>
  group_by(mu) |>
  summarize(power = mean(p.value < alpha), .groups = "drop") |>
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True Mean",
    y = "Power of the Test",
    title = "Power of One-Sample t-Test vs True Mean"
  ) +
  theme_minimal()
```

The power diagram shows that the power (the proportion rejecting the null hypothesis) increases rapidly as the true mean increases until the true mean reaches 4, the power stays at 1.



```{r, warning=FALSE, message=FALSE}
sim_results2 |>
  group_by(mu) |>
  summarize(
    mean_mu_hat = mean(estimate),
    mean_mu_hat_rejected = mean(estimate[p.value < alpha]),
    .groups = "drop"
  ) |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = mean_mu_hat), color = "blue", linetype = "solid", label = "All Samples") +
  geom_line(aes(y = mean_mu_hat_rejected), color = "red", linetype = "dashed", label = "Rejected H0") +
  geom_point(aes(y = mean_mu_hat), color = "blue") +
  geom_point(aes(y = mean_mu_hat_rejected), color = "red") +
  labs(
    x = "True Mean",
    y = "Average Estimate",
    title = "Average Estimate vs True Mean"
  ) +
  theme_minimal()
```


The solid blue line represents the average estimate for all samples, which is close to the true mean. The red dashed line indicates that the average estimate for the sample that rejects the null hypothesis is slightly higher than the true mean in the range from 1 to 4, and the gap decreases as the true mean increases. This is because the null hypothesis is more likely to be rejected only when the effect is large, resulting in higher estimates.


## Problem 3


```{r, warning=FALSE, message=FALSE}
homicide_df = read_csv("./data/homicide-data.csv") %>%
  janitor::clean_names() %>%
summary(homicide_df)
```

The dataset contains data on homicides in 50 major U.S. cities, including the reported date, the identity of the suspect, the location and the status of the case. There are `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns.


```{r}
homicide_df = homicide_df %>%
  mutate(city_state = str_c(city, ", ", state)) 

homicide_df |>
  group_by(city_state) |>
  summarize(total_homicides = n())
```


```{r}
homicide_df |>
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) |>
  group_by(city_state) |>
  summarize(unsolved_homicides = n())
```




